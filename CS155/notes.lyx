#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
CS 155 Machine Learning and Data Mining
\end_layout

\begin_layout Part*
Tuesday, January 5
\end_layout

\begin_layout Standard
Yay all lectures will be recorded.
 
\end_layout

\begin_layout Standard
Recitation is Thursday 7:30 to 9.
 
\end_layout

\begin_layout Standard
six assignments.
 2 mini projects and a final.
 so 9 thing that range from 10% to 16% of the grade.
\end_layout

\begin_layout Standard
With CS 156, the assignment should take 3-4 hours
\end_layout

\begin_layout Standard
Without then might take up 8-10 hours.
 but should catch you up.
\end_layout

\begin_layout Standard
Process of converting data and experience into knowledge.
 lots and lots of data into a computer model via some algorithm
\end_layout

\begin_layout Standard
ML is about algorithms and DM is about the knowledge extraction.
 want to make it human-understandable.
\end_layout

\begin_layout Standard
classifying emails by spam or not spam.
 can't just use if blocks.
 easy to recognize but hard t owrite down formula to describe which is spam
 and which isn't
\end_layout

\begin_layout Standard
use ML, we create a training set sorted by humans.
 then we create a generic representation and a learning algorithm so we
 can then classify properly.
 
\end_layout

\begin_layout Standard
we can use a bag of words represtnation.
 each email is a vector of numbers.
 it counts how many of each word in the dictionary.
 or can be booleans -- if that particular word is in the document.
 called a Feature Vector.
 
\end_layout

\begin_layout Standard
Linear models -- x is a bag of words representation of an email.
 linear classifier has a weight =vector and a bias so we multiple the weights
 by the words (0 or 1) and subtract a bias.
 then check the sign.
 want to make it so that we can perfectly classify the training set.
 then we guess it probably works elsewhere
\end_layout

\begin_layout Standard
there will be high weight on Nigerian Prince.
 ie it is usually spam.
 
\end_layout

\begin_layout Standard
2 ML problems: classification (which class does an object belong to
\begin_inset Formula $sign(w^{T}x-b)$
\end_inset

) and regression (predict a real value, so what is the confidence that something
 is spam 
\begin_inset Formula $w^{T}x-b$
\end_inset

.
 Now we have to care about false positives and negatives and things.
 
\end_layout

\begin_layout Subsubsection*
Formal Definitions:
\end_layout

\begin_layout Standard
Training Set 
\begin_inset Formula $S=\{(x_{i},y_{i})\}_{i=1}^{N}$
\end_inset


\end_layout

\begin_layout Standard
Model Class 
\begin_inset Formula $f(x|w;b)=w^{T}x-b$
\end_inset


\end_layout

\begin_layout Standard
Loss function (squared loss) 
\begin_inset Formula $L(a,b)=(a-b)^{2}$
\end_inset


\end_layout

\begin_layout Standard
Learning Objective minimize loss
\end_layout

\begin_layout Standard
Different loss functions: zero one loss -- all or nothing, just an indicator
 function.
 
\end_layout

\begin_layout Standard
squared loss is an upper bound on zero-one loss
\end_layout

\begin_layout Standard
zero one loss is discontinutous.
 can't compute the gradient there.
 very difficult to optimize.
 so we want to use squared loss becausethe gradient IS defined properly.
\end_layout

\begin_layout Standard
need to pull the training set peroperly from the true distribution.
\end_layout

\begin_layout Standard
overfitting is when test error is much larger than training error
\end_layout

\begin_layout Standard
variance/bias tradeoff is part of overfitting.
 
\end_layout

\begin_layout Standard
high variaince implies underfitting and high bias is ovrefittting
\end_layout

\begin_layout Standard

\end_layout

\end_body
\end_document
